criterion:
  name: mse

# aux_criterion:
#   swap_loss:
#     weight: 0.1
#   alm_loss:
#     weight: 0.1

optimizer:
  name: adamw
  lr: 0.0008
  weight_decay: 0.0001
  grad_clip_value: 1

scheduler:
  name: cosine
  lr_gamma: 0.99
  lr_min: 0

run:
  experiment: "navierstokes_meta_cnn_dno_train"
  n_epochs: 100
  batch_size: 32
  use_cuda: 1
  gpu_id: 0
  deterministic: 1
  log_interval: 200
  train_noise: 0
  grad_clip: False
  max_grad_value: 1
  do_distill: False

quantize:
  weight_bit: 8
  input_bit: 8
  
checkpoint:
  save_best_model_k: 3
  checkpoint_dir: "navierstokes/meta_cnn_dno/train"
  model_comment: ""
  resume: 0
  restore_checkpoint : ""

permutation:
  force_perm_legal_epoch: 70
  perm_loss_rho: 0.00001
  perm_loss_rho_gamma: 1.3
  warm_up_epoch: 5
  permutation_interval: 3
  rho_epoch: 15
  max_lambda: 10
  optimizer:
    name: adamw
    lr: 0.002
    weight_decay: 0
    grad_clip_value: 1
  n_epochs: 3000

model:
  name: "Meta_CNN_DNO"
  encode_mode: phase
  # skip_meta: False
  # delta_z: 8.42
  # lambda: 0.532
  # pixel_size: 0.4
  conv_cfg:
    type: MetaConv2d
    mode: phase
    w_bit: 8
    in_bit: 8
    path_multiplier: 1
    path_depth: 4
    weight_train: True
    skip_path: False
    scale_mode: bilinear
    skip_meta: False
    delta_z_data: 8.42
    lambda_data: 0.532
    pixel_size_data: 0.4
    ref_lambda: 0.532
    ref_pixel_size: 0.3
    enable_xy_pol: False # whether to use x/y polarization
    enable_alpha: [True, True]  # whether to use alpha factor for weighted input channel summation
    alpha_train: [True, True]  # whether to train alpha factor
    enable_beta: False  # whether to use beta factor as polarization angle for x direction
    delta_z_mode: fixed  # fixed, train_share, train, this one is reprogrammable
    pixel_size_mode: fixed  # fixed, train_share, train, this one is not reprogrammable after fabrication
    lambda_train: True  # Temperay
    delta_z_train: True  # Temperay
    pixel_size_train: True  # Temperay
    lambda_mode: fixed  # fixed, train_share, this one is reprogrammable after fabrication
    rotate_mode: fixed  # fixed, train, this one is reprogrammable after fabrication
    gumbel_mode: fixed  # gumbel_hard, gumbel_soft, softmax, random
    gumbel_T: 5
    beta_train: False  # whether to train beta factor
    gumbel_decay_rate: 0.956
    enable_identity: False  # whether to use identity phase mask, i.e., delta_phi=0, can be learned together with rotation
    swap_mode: fixed  # fixed, train_stage, train, this one is reprogrammable after fabrication
    encode_mode: phase
    pixel_size_res: 1 # nm
    delta_z_res: 10   # nm
    phase_res: 1      # degree
    lambda_res: 1     # nm
  prediction_conv_cfg:
    type: PTCBlockConv2d
    mode: "weight"
    miniblock: [1, 1, 16, 16]
    w_bit: 8
    in_bit: 8
  linear_cfg:
    type: PTCBlockLinear
    mode: "weight"
    miniblock: [1, 1, 16, 16]
    w_bit: 8
    in_bit: 8
  norm_cfg:
    type: BN2d
    affine: True
  act_cfg:
    type: GELU
    # inplace: True
  prediction_norm_cfg:
    type: BN2d
    affine: True
  prediction_act_cfg:
    type: GELU
    # inplace: True
  kernel_list: [32, 32]
  mid_channel_list: [32, 32]
  kernel_size_list: [32, 32]
  hidden_list: []
  stride_list: [1, 1]
  padding_list: [0, 0]
  dilation_list: [1, 1]
  groups_list: [32, 32]
  prediction_kernel_list: [64, 32]
  # prediction_mid_channel_list: [32, 32, 32, 32]
  prediction_kernel_size_list: [3, 1]
  prediction_hidden_list: []
  prediction_stride_list: [1, 1]
  prediction_padding_list: [1, 0]
  prediction_dilation_list: [1, 1]
  prediction_groups_list: [1, 1]
  pool_out_size: 5


debug:
  verboise: 1

